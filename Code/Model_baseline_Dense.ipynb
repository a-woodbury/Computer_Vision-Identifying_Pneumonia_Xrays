{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline model (fully connected)\n",
    "\n",
    "**Dense Network**\n",
    "- 2 Hidden Layers\n",
    "\n",
    "**Compiler**\n",
    "\n",
    "- loss function: binary crossentropy\n",
    "- optimizer: stochastic gradient descent\n",
    "\n",
    "**Fit**\n",
    "\n",
    "- 50 Epochs\n",
    "\n",
    "**Metrics**\n",
    "\n",
    "- Accuracy for train: .99 \n",
    "- Accuracy for val: .81\n",
    "\n",
    "**Assessment**\n",
    "- Our model is overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 20)                245780    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 147       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 245,973\n",
      "Trainable params: 245,973\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /Users/viviandang/opt/anaconda3/lib/python3.7/site-packages (4.2.0.34)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /Users/viviandang/opt/anaconda3/lib/python3.7/site-packages (from opencv-python) (1.17.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "!{sys.executable} -m pip install opencv-python\n",
    "\n",
    "import time\n",
    "import scipy\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale and Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folder = 'data/test'\n",
    "train_folder = 'data/train'\n",
    "val_folder = 'data/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 624 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n",
      "Found 5216 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# get all the data in the directory split/test (180 images), and reshape them\n",
    "test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(test_folder, \n",
    "        target_size=(64, 64), batch_size = 624 ) \n",
    "\n",
    "# get all the data in the directory split/validation (200 images), and reshape them\n",
    "val_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(val_folder, \n",
    "        target_size=(64, 64), batch_size = 16)\n",
    "\n",
    "# get all the data in the directory split/train (542 images), and reshape them\n",
    "train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(train_folder, \n",
    "        target_size=(64, 64), batch_size = 5216)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = next(train_generator)\n",
    "test_images, test_labels = next(test_generator)\n",
    "val_images, val_labels = next(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 5216\n",
      "Number of testing samples: 624\n",
      "Number of validation samples: 16\n",
      "train_images shape: (5216, 64, 64, 3)\n",
      "train_labels shape: (5216, 2)\n",
      "test_images shape: (624, 64, 64, 3)\n",
      "test_labels shape: (624, 2)\n",
      "val_images shape: (16, 64, 64, 3)\n",
      "val_labels shape: (16, 2)\n"
     ]
    }
   ],
   "source": [
    "# Explore your dataset again\n",
    "m_train = train_images.shape[0]\n",
    "num_px = train_images.shape[1]\n",
    "m_test = test_images.shape[0]\n",
    "m_val = val_images.shape[0]\n",
    "\n",
    "print (\"Number of training samples: \" + str(m_train))\n",
    "print (\"Number of testing samples: \" + str(m_test))\n",
    "print (\"Number of validation samples: \" + str(m_val))\n",
    "print (\"train_images shape: \" + str(train_images.shape))\n",
    "print (\"train_labels shape: \" + str(train_labels.shape))\n",
    "print (\"test_images shape: \" + str(test_images.shape))\n",
    "print (\"test_labels shape: \" + str(test_labels.shape))\n",
    "print (\"val_images shape: \" + str(val_images.shape))\n",
    "print (\"val_labels shape: \" + str(val_labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5216, 12288)\n",
      "(624, 12288)\n",
      "(16, 12288)\n"
     ]
    }
   ],
   "source": [
    "train_img = train_images.reshape(train_images.shape[0], -1)\n",
    "test_img = test_images.reshape(test_images.shape[0], -1)\n",
    "val_img = val_images.reshape(val_images.shape[0], -1)\n",
    "\n",
    "print(train_img.shape)\n",
    "print(test_img.shape)\n",
    "print(val_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.reshape(train_labels[:,0], (5216,1))\n",
    "test_y = np.reshape(test_labels[:,0], (624,1))\n",
    "val_y = np.reshape(val_labels[:,0], (16,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating X-y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a baseline fully connected model\n",
    "from keras import models\n",
    "from keras import layers\n",
    "np.random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(20, activation='relu', input_shape=(12288,))) # 2 hidden layers\n",
    "model.add(layers.Dense(7, activation='relu'))\n",
    "model.add(layers.Dense(5, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5216 samples, validate on 16 samples\n",
      "Epoch 1/50\n",
      "5216/5216 [==============================] - 1s 128us/step - loss: 0.4246 - accuracy: 0.8085 - val_loss: 0.6164 - val_accuracy: 0.7500\n",
      "Epoch 2/50\n",
      "5216/5216 [==============================] - 0s 95us/step - loss: 0.2656 - accuracy: 0.8923 - val_loss: 0.4456 - val_accuracy: 0.8125\n",
      "Epoch 3/50\n",
      "5216/5216 [==============================] - 0s 81us/step - loss: 0.2024 - accuracy: 0.9225 - val_loss: 0.5388 - val_accuracy: 0.8125\n",
      "Epoch 4/50\n",
      "5216/5216 [==============================] - 0s 83us/step - loss: 0.1831 - accuracy: 0.9262 - val_loss: 0.8253 - val_accuracy: 0.6250\n",
      "Epoch 5/50\n",
      "5216/5216 [==============================] - 0s 86us/step - loss: 0.1654 - accuracy: 0.9329 - val_loss: 1.0173 - val_accuracy: 0.6250\n",
      "Epoch 6/50\n",
      "5216/5216 [==============================] - 0s 83us/step - loss: 0.1469 - accuracy: 0.9431 - val_loss: 0.3601 - val_accuracy: 0.8750\n",
      "Epoch 7/50\n",
      "5216/5216 [==============================] - 0s 87us/step - loss: 0.1365 - accuracy: 0.9467 - val_loss: 0.2392 - val_accuracy: 0.9375\n",
      "Epoch 8/50\n",
      "5216/5216 [==============================] - 0s 83us/step - loss: 0.1407 - accuracy: 0.9454 - val_loss: 0.2333 - val_accuracy: 0.9375\n",
      "Epoch 9/50\n",
      "5216/5216 [==============================] - 0s 83us/step - loss: 0.1360 - accuracy: 0.9471 - val_loss: 0.2223 - val_accuracy: 0.9375\n",
      "Epoch 10/50\n",
      "5216/5216 [==============================] - 0s 78us/step - loss: 0.1380 - accuracy: 0.9459 - val_loss: 1.0522 - val_accuracy: 0.6250\n",
      "Epoch 11/50\n",
      "5216/5216 [==============================] - 0s 87us/step - loss: 0.1300 - accuracy: 0.9507 - val_loss: 0.4801 - val_accuracy: 0.8125\n",
      "Epoch 12/50\n",
      "5216/5216 [==============================] - 0s 87us/step - loss: 0.1183 - accuracy: 0.9551 - val_loss: 0.8682 - val_accuracy: 0.6875\n",
      "Epoch 13/50\n",
      "5216/5216 [==============================] - 0s 85us/step - loss: 0.1251 - accuracy: 0.9525 - val_loss: 0.9466 - val_accuracy: 0.6250\n",
      "Epoch 14/50\n",
      "5216/5216 [==============================] - 0s 80us/step - loss: 0.1236 - accuracy: 0.9536 - val_loss: 0.2822 - val_accuracy: 0.9375\n",
      "Epoch 15/50\n",
      "5216/5216 [==============================] - 0s 83us/step - loss: 0.1170 - accuracy: 0.9555 - val_loss: 0.2229 - val_accuracy: 0.9375\n",
      "Epoch 16/50\n",
      "5216/5216 [==============================] - 0s 85us/step - loss: 0.1189 - accuracy: 0.9561 - val_loss: 0.5533 - val_accuracy: 0.7500\n",
      "Epoch 17/50\n",
      "5216/5216 [==============================] - 0s 83us/step - loss: 0.1116 - accuracy: 0.9599 - val_loss: 0.4251 - val_accuracy: 0.8125\n",
      "Epoch 18/50\n",
      "5216/5216 [==============================] - 0s 85us/step - loss: 0.1091 - accuracy: 0.9582 - val_loss: 0.6398 - val_accuracy: 0.6875\n",
      "Epoch 19/50\n",
      "5216/5216 [==============================] - 0s 82us/step - loss: 0.1124 - accuracy: 0.9574 - val_loss: 0.6618 - val_accuracy: 0.6875\n",
      "Epoch 20/50\n",
      "5216/5216 [==============================] - 0s 82us/step - loss: 0.1100 - accuracy: 0.9586 - val_loss: 0.1843 - val_accuracy: 0.9375\n",
      "Epoch 21/50\n",
      "5216/5216 [==============================] - 0s 86us/step - loss: 0.1161 - accuracy: 0.9551 - val_loss: 0.3059 - val_accuracy: 0.9375\n",
      "Epoch 22/50\n",
      "5216/5216 [==============================] - 0s 88us/step - loss: 0.1053 - accuracy: 0.9613 - val_loss: 0.3779 - val_accuracy: 0.8125\n",
      "Epoch 23/50\n",
      "5216/5216 [==============================] - 0s 87us/step - loss: 0.1074 - accuracy: 0.9595 - val_loss: 0.3339 - val_accuracy: 0.9375\n",
      "Epoch 24/50\n",
      "5216/5216 [==============================] - 0s 88us/step - loss: 0.1033 - accuracy: 0.9615 - val_loss: 0.5211 - val_accuracy: 0.7500\n",
      "Epoch 25/50\n",
      "5216/5216 [==============================] - 0s 87us/step - loss: 0.1010 - accuracy: 0.9624 - val_loss: 0.7192 - val_accuracy: 0.6875\n",
      "Epoch 26/50\n",
      "5216/5216 [==============================] - 0s 80us/step - loss: 0.1047 - accuracy: 0.9599 - val_loss: 0.2880 - val_accuracy: 0.9375\n",
      "Epoch 27/50\n",
      "5216/5216 [==============================] - 0s 81us/step - loss: 0.1033 - accuracy: 0.9622 - val_loss: 0.4202 - val_accuracy: 0.8125\n",
      "Epoch 28/50\n",
      "5216/5216 [==============================] - 0s 87us/step - loss: 0.1039 - accuracy: 0.9599 - val_loss: 0.4845 - val_accuracy: 0.8125\n",
      "Epoch 29/50\n",
      "5216/5216 [==============================] - 0s 85us/step - loss: 0.1023 - accuracy: 0.9620 - val_loss: 0.2676 - val_accuracy: 0.9375\n",
      "Epoch 30/50\n",
      "5216/5216 [==============================] - 0s 83us/step - loss: 0.0973 - accuracy: 0.9624 - val_loss: 0.3976 - val_accuracy: 0.8125\n",
      "Epoch 31/50\n",
      "5216/5216 [==============================] - 0s 83us/step - loss: 0.0972 - accuracy: 0.9618 - val_loss: 0.3528 - val_accuracy: 0.8750\n",
      "Epoch 32/50\n",
      "5216/5216 [==============================] - 0s 84us/step - loss: 0.0898 - accuracy: 0.9657 - val_loss: 0.6941 - val_accuracy: 0.6875\n",
      "Epoch 33/50\n",
      "5216/5216 [==============================] - 0s 79us/step - loss: 0.0942 - accuracy: 0.9647 - val_loss: 0.4361 - val_accuracy: 0.8125\n",
      "Epoch 34/50\n",
      "5216/5216 [==============================] - 0s 81us/step - loss: 0.0930 - accuracy: 0.9630 - val_loss: 0.4073 - val_accuracy: 0.8125\n",
      "Epoch 35/50\n",
      "5216/5216 [==============================] - 0s 81us/step - loss: 0.0918 - accuracy: 0.9647 - val_loss: 0.3345 - val_accuracy: 0.8750\n",
      "Epoch 36/50\n",
      "5216/5216 [==============================] - 0s 88us/step - loss: 0.0911 - accuracy: 0.9664 - val_loss: 0.6345 - val_accuracy: 0.6875\n",
      "Epoch 37/50\n",
      "5216/5216 [==============================] - 0s 82us/step - loss: 0.1006 - accuracy: 0.9634 - val_loss: 1.0380 - val_accuracy: 0.6250\n",
      "Epoch 38/50\n",
      "5216/5216 [==============================] - 0s 80us/step - loss: 0.0897 - accuracy: 0.9661 - val_loss: 0.2639 - val_accuracy: 0.9375\n",
      "Epoch 39/50\n",
      "5216/5216 [==============================] - 0s 80us/step - loss: 0.0884 - accuracy: 0.9666 - val_loss: 0.4611 - val_accuracy: 0.8125\n",
      "Epoch 40/50\n",
      "5216/5216 [==============================] - 0s 82us/step - loss: 0.0843 - accuracy: 0.9688 - val_loss: 0.4168 - val_accuracy: 0.8125\n",
      "Epoch 41/50\n",
      "5216/5216 [==============================] - 0s 79us/step - loss: 0.0828 - accuracy: 0.9699 - val_loss: 0.4187 - val_accuracy: 0.8125\n",
      "Epoch 42/50\n",
      "5216/5216 [==============================] - 0s 82us/step - loss: 0.0858 - accuracy: 0.9686 - val_loss: 0.4420 - val_accuracy: 0.8125\n",
      "Epoch 43/50\n",
      "5216/5216 [==============================] - 0s 80us/step - loss: 0.0832 - accuracy: 0.9649 - val_loss: 0.2388 - val_accuracy: 0.8750\n",
      "Epoch 44/50\n",
      "5216/5216 [==============================] - 0s 80us/step - loss: 0.0856 - accuracy: 0.9689 - val_loss: 0.3298 - val_accuracy: 0.8750\n",
      "Epoch 45/50\n",
      "5216/5216 [==============================] - 0s 83us/step - loss: 0.0816 - accuracy: 0.9695 - val_loss: 0.3953 - val_accuracy: 0.8125\n",
      "Epoch 46/50\n",
      "5216/5216 [==============================] - 0s 83us/step - loss: 0.0746 - accuracy: 0.9730 - val_loss: 1.0899 - val_accuracy: 0.6250\n",
      "Epoch 47/50\n",
      "5216/5216 [==============================] - 0s 83us/step - loss: 0.0800 - accuracy: 0.9688 - val_loss: 0.6565 - val_accuracy: 0.6875\n",
      "Epoch 48/50\n",
      "5216/5216 [==============================] - 0s 83us/step - loss: 0.0815 - accuracy: 0.9688 - val_loss: 0.1980 - val_accuracy: 0.8750\n",
      "Epoch 49/50\n",
      "5216/5216 [==============================] - 0s 83us/step - loss: 0.0769 - accuracy: 0.9720 - val_loss: 0.5727 - val_accuracy: 0.7500\n",
      "Epoch 50/50\n",
      "5216/5216 [==============================] - 0s 83us/step - loss: 0.0771 - accuracy: 0.9724 - val_loss: 0.6637 - val_accuracy: 0.7500\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "histoire = model.fit(train_img,\n",
    "                    train_y,\n",
    "                    epochs=50,\n",
    "                    batch_size=16,\n",
    "                    validation_data=(val_img, val_y), verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5216/5216 [==============================] - 0s 27us/step\n"
     ]
    }
   ],
   "source": [
    "results_train = model.evaluate(train_img, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.07644408498747857, 0.970475435256958]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 84us/step\n"
     ]
    }
   ],
   "source": [
    "results_val = model.evaluate(val_img, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6636800765991211, 0.75]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
