{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model: CNN\n",
    "\n",
    "**Neural Network**\n",
    "- 2 Hidden Layers, 2 Dropouts\n",
    "\n",
    "**Compiler**\n",
    "\n",
    "- loss function: binary crossentropy\n",
    "- optimizer: adam\n",
    "\n",
    "**Fit**\n",
    "\n",
    "- 7 Epochs\n",
    "\n",
    "**Metrics**\n",
    "- Recall for train: .96 \n",
    "- Recall for val: .875\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 254, 254, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 84, 84, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 84, 84, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 84, 84, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 84, 84, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 5184)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 5185      \n",
      "=================================================================\n",
      "Total params: 74,945\n",
      "Trainable params: 74,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#!{sys.executable} -m pip install opencv-python\n",
    "\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import keras_metrics\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score, GridSearchCV, validation_curve \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix, r2_score, recall_score, precision_score, f1_score, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, validation_curve\n",
    "from sklearn.pipeline import make_pipeline\n",
    "#from tensorflow.keras import get_default_graph\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix code\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion Matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 1\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define data path\n",
    "test_folder = 'Data/test'\n",
    "train_folder = 'data/train'\n",
    "val_folder = 'data/val'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep data for processing\n",
    "test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        test_folder, \n",
    "        target_size=(256,256), batch_size = 627) \n",
    "\n",
    "val_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        val_folder, \n",
    "        target_size=(256,256), batch_size = 19)\n",
    "\n",
    "train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        train_folder, \n",
    "        target_size=(256,256), batch_size=5219)\n",
    "\n",
    "train_images, train_labels = next(train_generator)\n",
    "test_images, test_labels = next(test_generator)\n",
    "val_images, val_labels = next(val_generator)\n",
    "\n",
    "train_img = train_images.reshape(train_images.shape[0], -1)\n",
    "test_img = test_images.reshape(test_images.shape[0], -1)\n",
    "val_img = val_images.reshape(val_images.shape[0], -1)\n",
    "\n",
    "train_y = np.reshape(train_labels[:,0], (5216,1))\n",
    "test_y = np.reshape(test_labels[:,0], (624,1))\n",
    "val_y = np.reshape(val_labels[:,0], (16,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "624"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking <tf.Variable 'Variable_2:0' shape=() dtype=int32> tp\n",
      "tracking <tf.Variable 'Variable_3:0' shape=() dtype=int32> fn\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 254, 254, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 84, 84, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 84, 84, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 84, 84, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 84, 84, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 5184)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 5185      \n",
      "=================================================================\n",
      "Total params: 74,945\n",
      "Trainable params: 74,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(16, (3, 3), activation='relu',\n",
    "                        input_shape=(256 ,256,  3)))\n",
    "model.add(layers.MaxPooling2D((3, 3)))\n",
    "model.add(layers.Dropout(0.05))  \n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', padding=\"same\"))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', padding=\"same\"))\n",
    "model.add(layers.MaxPooling2D((3, 3)))\n",
    "model.add(layers.Dropout(0.05))  \n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', padding=\"same\"))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', padding=\"same\"))\n",
    "model.add(layers.MaxPooling2D((3, 3)))\n",
    "#model.add(layers.Dropout(0.0025)) \n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "# model.add(layers.Flatten())\n",
    "\n",
    "# model.add(layers.Dense(64, activation='relu'))\n",
    "# #model.add(layers.Dropout(0.4))\n",
    "# model.add(layers.Dense(2 , activation='softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc',keras_metrics.recall()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4694 samples, validate on 522 samples\n",
      "Epoch 1/7\n",
      "4694/4694 [==============================] - 133s 28ms/step - loss: 0.3356 - acc: 0.8479 - recall: 0.3082 - val_loss: 0.1176 - val_acc: 0.9559 - val_recall: 0.9290\n",
      "Epoch 2/7\n",
      "4694/4694 [==============================] - 123s 26ms/step - loss: 0.1163 - acc: 0.9589 - recall: 0.9076 - val_loss: 0.0785 - val_acc: 0.9636 - val_recall: 0.8889\n",
      "Epoch 3/7\n",
      "4694/4694 [==============================] - 127s 27ms/step - loss: 0.0891 - acc: 0.9687 - recall: 0.9490 - val_loss: 0.0722 - val_acc: 0.9674 - val_recall: 0.8835\n",
      "Epoch 4/7\n",
      "4694/4694 [==============================] - 122s 26ms/step - loss: 0.0769 - acc: 0.9700 - recall: 0.9324 - val_loss: 0.0685 - val_acc: 0.9732 - val_recall: 0.9346\n",
      "Epoch 5/7\n",
      "4694/4694 [==============================] - 122s 26ms/step - loss: 0.0690 - acc: 0.9742 - recall: 0.9492 - val_loss: 0.0803 - val_acc: 0.9713 - val_recall: 0.9414\n",
      "Epoch 6/7\n",
      "4694/4694 [==============================] - 130s 28ms/step - loss: 0.0588 - acc: 0.9785 - recall: 0.9631 - val_loss: 0.0653 - val_acc: 0.9808 - val_recall: 0.9203\n",
      "Epoch 7/7\n",
      "4694/4694 [==============================] - 142s 30ms/step - loss: 0.0577 - acc: 0.9798 - recall: 0.9611 - val_loss: 0.0560 - val_acc: 0.9770 - val_recall: 0.9238\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_images,\n",
    "                    train_y,\n",
    "                    epochs=7,\n",
    "                    batch_size=32,\n",
    "                    validation_split= 0.1,\n",
    "                    #validation_data=(val_images, val_y)\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5216/5216 [==============================] - 56s 11ms/step\n",
      "16/16 [==============================] - 0s 19ms/step\n"
     ]
    }
   ],
   "source": [
    "results_train = model.evaluate(train_images, train_y)\n",
    "results_test = model.evaluate(val_images, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.03979605585629509, 0.9838957190513611, 0.997648298740387]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.11767389625310898, 0.9375, 0.875]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix, without normalization\n",
      "[[8 0]\n",
      " [1 7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      1.00      0.94         8\n",
      "         1.0       1.00      0.88      0.93         8\n",
      "\n",
      "    accuracy                           0.94        16\n",
      "   macro avg       0.94      0.94      0.94        16\n",
      "weighted avg       0.94      0.94      0.94        16\n",
      "\n",
      "roc_auc_score: 0.9375\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = model.predict_classes(val_images)\n",
    "\n",
    "cm = confusion_matrix(val_y, y_pred)\n",
    "classes = ['Negative', 'Positive']\n",
    "\n",
    "plot_confusion_matrix(cm, classes,\n",
    "                      normalize=False,\n",
    "                      title='Confusion matrix'\n",
    "                     )\n",
    "plt.figsize=(10,10)\n",
    "plt.savefig('Images/conf.png')\n",
    "#Checking performance our model with classification report.\n",
    "print(classification_report(val_y, y_pred))\n",
    "#Checking performance our model with ROC Score.\n",
    "print ('roc_auc_score:', roc_auc_score(val_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
